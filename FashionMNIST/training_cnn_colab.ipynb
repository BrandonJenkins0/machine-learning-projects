{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try out some data augmentation to make it better.\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to clean up the work flow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "def load_data(file_path=\"FashionMNIST/data/fashion_mnist_scaled.npz\"):\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "    X_train, y_train, X_test, y_test = [data[file] for file in data.files]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Getting an augmented dataset\n",
    "def augmenting_data(gen, X, y, num_augmented_imgs=5):\n",
    "    aug_iter = gen.flow(X, y, batch_size=len(X))\n",
    "    data = [next(aug_iter) for num in range(num_augmented_imgs)]\n",
    "    y1 = [data[num][1] for num in range(num_augmented_imgs)]\n",
    "    x = [data[num][0] for num in range(num_augmented_imgs)]\n",
    "    return np.concatenate([np.vstack(x), X]), np.concatenate([np.vstack(y1).reshape(-1), y])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "X_train, y_train, X_test, y_test = load_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating image generator\n",
    "gen = ImageDataGenerator(rotation_range=10, width_shift_range=.1, zoom_range=.1,\n",
    "                         horizontal_flip=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating augmented dataset\n",
    "X_train_augmented, y_train_augmented = augmenting_data(gen, X_train, y_train, 2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Callbacks for training\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
    "callbacks = [es, mcp_save, reduce_lr_loss]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Making a deeper model architecture\n",
    "model2 = Sequential([\n",
    "    Conv2D(120, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(60, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(30, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compiling the simple model\n",
    "model2.compile(Adam(.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fitting model with specifying validation set\n",
    "model2.fit(X_train_augmented, y_train_augmented, validation_split=.1, epochs=100,\n",
    "           callbacks=callbacks, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}